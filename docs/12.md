

# 12 建模分类关系

到目前为止，我们已经讨论了统计建模和假设检验的一般概念，并将其应用于一些简单的分析；现在我们将转向如何在我们的数据中对特定类型的关系建模的问题。在本章中，我们将重点关注*分类*关系的建模，我们指的是定性测量的变量之间的关系。这些数据通常用计数来表示；也就是说，对于变量的每个值(或多个变量的值的组合)，有多少个观测值取该值？例如，当我们计算我们班每个专业有多少人时，我们是在为数据拟合一个分类模型。



## 12.1 示例:糖果色

比方说，我购买了一袋 100 颗糖果，标签上标明有 1/3 巧克力、1/3 巧克力糖和 1/3 口香糖。当我数袋子里的糖果时，我们得到了下面的数字:30 块巧克力，33 块巧克力糖和 37 块口香糖球。因为比起甘草糖或口香糖，我更喜欢巧克力，所以我觉得有点被骗了，我想知道这是否只是一个偶然事件。要回答这个问题，我需要知道:如果每种糖果类型的真实概率是每种糖果的 1/3 的平均比例，那么计数结果是这样的可能性有多大？





## 12.2 皮尔森卡方检验

Pearson 卡方检验为我们提供了一种方法来检验一组观察计数是否不同于定义零假设的某些特定期望值:

<semantics><mrow><mo>=</mo> <msub><mi><mi>【I】</mi></mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mrow><mi>和</mi></mrow></semantics>

在我们的糖果例子中，零假设是每种糖果的比例相等。为了计算卡方统计量，我们首先需要在零假设下得出我们的预期计数:因为零假设是它们都是相同的，那么这就是跨三个类别的总计数(如表 [12.1](#tab:candyDf) 所示)。然后，我们取每个计数与其在零假设下的期望值之间的差，将它们平方，除以零期望值，然后将它们相加，得到卡方统计量。

<caption>Table 12.1: Observed counts, expectations under the null hypothesis, and squared differences in the candy data</caption>
| 糖果型 | 数数 | null 期望 | 平方差 |
| --- | --- | --- | --- |
| 巧克力 | Thirty | Thirty-three | Eleven point one one |
| 欧亚甘草 | Thirty-three | Thirty-three | Zero point one one |
| 球形口香糖 | Thirty-seven | Thirty-three | Thirteen point four four |

此分析的卡方统计结果为 0.74，这本身是不可解释的，因为它取决于不同值相加的数量。但是，我们可以利用卡方统计量是根据零假设下的特定分布分布的这一事实，这种分布称为*卡方*分布。这个分布被定义为一组标准正态随机变量的平方和；它的自由度数量等于变量相加的数量。分布的形状取决于自由度的数量。图 [12.1](#fig:chisqDist) 的左图显示了几个不同自由度的分布示例。

![Left: Examples of the chi-squared distribution for various degrees of freedom.  Right: Simulation of sum of squared random normal variables.   The histogram is based on the sum of squares of 50,000 sets of 8 random normal variables; the dotted line shows the values of the theoretical chi-squared distribution with 8 degrees of freedom.](img/file66.png)

图 12.1:左图:不同自由度的卡方分布示例。右图:随机正态变量平方和的模拟。直方图基于 5 万组 8 个随机正态变量的平方和；虚线显示了具有 8 个自由度的理论卡方分布的值。

让我们使用模拟来验证卡方分布是否准确描述了一组标准正态随机变量的平方和。为了做到这一点，我们反复抽取 8 个随机数的集合，并在平方每个值后将每个集合相加。图 [12.1](#fig:chisqDist) 的右图显示，理论分布与一组随机正态变量的平方反复相加的模拟结果非常匹配。

以糖果为例，在所有糖果频率相等的零假设下，我们可以计算观察到的卡方值为 0.74 的可能性。我们使用自由度等于 k - 1(其中 k =类别数)的卡方分布，因为我们在计算平均值以生成期望值时损失了一个自由度。得到的 P 值(P(卡方)> 0.74 = 0.691)表明，根据糖果袋上印刷的比例，观察到的糖果数量并不特别令人惊讶，我们不会拒绝相等比例的无效假设。





## 12.3 列联表和双向检验

我们经常使用卡方检验的另一种方法是询问两个分类变量是否彼此相关。作为一个更现实的例子，让我们来看看这样一个问题:与白人司机相比，黑人司机在被警察拦下时是否更容易被搜查。斯坦福开放警务项目([https://openpolicing.stanford.edu/](https://openpolicing.stanford.edu/))对此进行了研究，并提供了我们可以用来分析这个问题的数据。我们将使用康涅狄格州的数据，因为它们相当小，因此更容易分析。

表示分类分析数据的标准方式是通过*列联表*，该表显示了落入每个变量的每个可能值组合中的观察值的数量或比例。下表 [12.2](#tab:policeCT) 显示了警方搜索数据的列联表。使用比例而不是原始数字来查看列联表也是有用的，因为它们更容易直观地比较，所以我们在这里包括绝对数字和相对数字。

<caption>Table 12.2: Contingency table for police search data</caption>
| 搜查 | 黑色 | 白色的 | 黑色(相对) | 白色(相对) |
| --- | --- | --- | --- | --- |
| 错误的 | Thirty-six thousand two hundred and forty-four | Two hundred and thirty-nine thousand two hundred and forty-one | Zero point one three | Zero point eight six |
| 真实的 | One thousand two hundred and nineteen | Three thousand one hundred and eight | Zero | Zero point zero one |

皮尔逊卡方检验允许我们测试观察到的频率是否与预期的频率不同，因此我们需要确定如果搜索和种族不相关，我们在每个细胞中预期的频率是多少——我们可以定义为*独立。*记住概率一章，如果 X 和 Y 是独立的，那么:

<math xmlns:epub="http://www.idpf.org/2007/ops" display="block"><semantics><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>X</mi>∩<mi>Y</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi><mo stretchy="true" form="postfix">)</mo></mi></mrow><mo>*</mo><mi>P</mi><mrow><mrow><mo stretchy="true" form="prefix">边际概率就是不管其他事件如何，每个事件发生的概率。我们可以计算出那些边际概率，然后把它们相乘得到独立情况下的期望比例。</mo></mrow></mrow></mrow></semantics></math>

|  | 黑色 | 白色的 |  |
| --- | --- | --- | --- |
| 未搜索 | 页:1 | 页:1 | 生理盐水 |
| 搜查 | P(S)*P(B) | P(S)*P(W) | P(S) |
|  | P(B) | P(W) |  |

然后，我们计算卡方统计，得出 828.3。要计算 p 值，我们需要将其与零卡方分布进行比较，以确定我们的卡方值与零假设下的预期值相比有多极端。这种分布的自由度是<math xmlns:epub="http://www.idpf.org/2007/ops" display="inline"><semantics><mrow><mi>d</mi><mi>f</mi><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>n</mi><mi>R</mi><mi>o</mi><mi>w</mi><mi>s</mi><mn>1</mn></mrow><mo>*</mo> <mrow><mo stretchy="true" form="prefix">(</mo><mi>n</mi><mi>C</mi><mi>o</mi><mi>l</mi><mi>u</mi><mi>m</mi><mi>n</mi><mi>s</mi><mo>-</mo></mrow><annotation encoding="application/x-tex">df =(nRows-1)*(nColumns-1) <math xmlns:epub="http://www.idpf.org/2007/ops" display="inline"><semantics><mrow><mi>d</mi><mi>f</mi><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>2</mn><mo>—</mo>—T78】1</mrow><mo>*</mo><mrow><mo stretchy="true" form="prefix">(</mo><mn>2</mn> 这里的直觉是，计算预期频率需要我们使用三个值:观察的总数和两个变量的边际概率。因此，一旦计算出这些值，只有一个数字可以自由变化，因此有一个自由度。考虑到这一点，我们可以计算卡方统计的 p 值，它几乎接近于零:<math xmlns:epub="http://www.idpf.org/2007/ops" display="inline"><semantics><mrow><mn>3.79</mn><mo>×</mo><msup><mn>10</mn><mrow><mo>—</mo><mn>182</mn></mrow></msup></mrow><annotation encoding="application/x-tex">3.79 \次 10^{-182}<annotation encoding="application/x-tex">这表明，如果种族和警察搜查之间真的没有关系，观察到的数据将是极不可能的，因此我们应该拒绝独立性的零假设。</annotation></annotation></semantics></math></mrow></mrow></semantics></math></annotation></mrow></semantics></math>

我们还可以使用我们的统计软件轻松执行该测试:

```
## 
##  Pearson's Chi-squared test
## 
## data:  summaryDf2wayTable and 1
## X-squared = 828, df = 1, p-value <2e-16
```





## 12.4 标准化残差

当我们发现卡方检验有显著影响时，这告诉我们数据在零假设下不太可能，但它没有告诉我们*数据如何*不同。为了更深入地了解数据与我们在零假设下的预期有何不同，我们可以检查模型的残差，它反映了每个像元中数据(即观察到的频率)与模型(即预期的频率)的偏差。与其查看原始残差(其变化仅取决于数据中的观测值数量)，不如查看*标准化残差*(有时也称为*皮尔逊残差*)，其计算方法如下:

<math xmlns:epub="http://www.idpf.org/2007/ops" display="block"><semantics><mrow><mi>s</mi><mi>t</mi><mi>a</mi><mi>n</mi><mi>d</mi><mi>a</mi><mi>r</mi><mi>d</mi><mi>I</mi><mi>z</mi><mi>e</mi><mi>d</mi>r<mi>e</mi><mi>s</mi> <mi>b</mi><mi>s</mi><mi>e</mi><mi>r</mi><mi>v</mi><mi>e</mi><msub><mi>d</mi><mrow><mi>I</mi><mi>j</mi></mrow></msub><mi>e</mi> <mi><mi>e</mi><mi>c</mi><mi>t</mi><mi>e</mi><msub><mi>d</mi><mrow><mi>I</mi><mi>j</mi></mrow></msub></mi></mrow><annotation encoding="application/x-tex">标准化\残差 _{ij} = \frac{observed_{ij} -预期</annotation></semantics></math>

表 [12.3](#tab:stdRes) 显示了这些警察停车数据。这些标准化的残差可以解释为 Z 分数——在这种情况下，我们看到黑人个体的搜索次数大大高于基于独立性的预期，白人个体的搜索次数大大低于预期。这为我们提供了解释显著的卡方检验结果所需的背景。

<caption>Table 12.3: Summary of standardized residuals for police stop data</caption>
| 搜查 | 车手 _ 比赛 | 标准化残差 |
| --- | --- | --- |
| 错误的 | 黑色 | -3.3 |
| 真实的 | 黑色 | Twenty-six point six |
| 错误的 | 白色的 | One point three |
| 真实的 | 白色的 | -10.4 |





## 12.5 优势比

为了更好地理解影响的大小，我们还可以在列联表中用我们前面介绍的比值比来表示不同结果的相对可能性。首先，我们表示每场比赛被停止的几率，然后我们计算它们的比率:

<semantics><mrow><mi>或</mi> <mi><mi><msub><mi><mi>b</mi><mi>l</mi><mi>a</mi><mo>= <mo><mi><mspace width="0.222em"><mi>【s】</mi>【e】<mi>【a】</mi>【r】<mi>【c】</mi></mspace></mi></mo></mo></mi></msub></mi></mi></mrow></semantics>

<semantics><mrow><mi>或</mi><mi><mi><msub><mi><mi><mi>【h】<mi><mi>【我】</mi></mi><mi><mo>=</mo></mi><mi><mspace width="0.222em"><mi>【s】</mi>【e】</mspace></mi><mi>【a】</mi>【r】</mi><mi>【c】</mi> 已搜索\ cap white } } = \ frac { 3108 } { 239241 } = 0.013<math xmlns:epub="http://www.idpf.org/2007/ops" display="block"><semantics><mi><mi><mi><mi><mi>【T1148】</mi> <mi>【b】</mi><mi>【l】</mi><mi>【a】</mi>【c】</mi><mi>【k】</mi></mi></mi></mi></semantics></math></mi></mi></msub></mi></mi></mrow></semantics>

根据这个数据集，赔率显示，黑人司机被搜索的几率是白人司机的 2.59 倍。





## 12.6 贝叶斯因子

我们在前面关于贝叶斯统计的章节中讨论过贝叶斯因子——你可能记得它代表了两种假设下数据的可能性的比率:<math xmlns:epub="http://www.idpf.org/2007/ops" display="block"><semantics><mrow><mi>K</mi><mo>=</mo><mfrac><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>d</mi><mi>A</mi><mi>t</mi><mi>A</mi>|<msub><mi>H</mi></msub></mrow></mrow> <mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><mi>d</mi><mi>A</mi><mi>t</mi><mi>A</mi><mo stretchy="false" form="prefix">|</mo><msub><mi>H</mi><mo stretchy="true" form="postfix">)</mo></msub></mrow></mrow></mfrac><mo>=</mo> <mfrac><mfrac><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>H</mi><mi>A</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow></mfrac></mfrac></mrow><mrow><mi>P</mi><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>H</mi><mn>0</mn></msub><mo stretchy="false" form="prefix">|)</mo></mrow></mrow> <annotation encoding="application/x-tex">K = \ frac { P(data | H _ A)} { P(data | H _ 0)} = \ frac { P(H _ A | data)* P(H _ A)} { P(H _ 0 | data)* P(H _ 0)}</annotation></semantics></math>我们可以使用我们的统计软件计算警方搜索数据的贝叶斯因子:

```
## Bayes factor analysis
## --------------
## [1] Non-indep. (a=1) : 1.8e+142 ±0%
## 
## Against denominator:
##   Null, independence, a = 1 
## ---
## Bayes factor type: BFcontingencyTable, independent multinomial
```

这表明，在这个数据集中，有利于司机种族和警察搜索之间关系的证据非常有力——<math display="inline"><semantics><mrow><mn>1.8</mn><mo>*</mo><msup><mn>10</mn><mn>142</mn></msup></mrow><annotation encoding="application/x-tex">1.8 * 10^{142}</annotation></semantics></math>大约是我们在统计中可以想象得到的接近无穷大。





## 12.7 超出 2 X 2 表格的分类分析

类别分析也可以应用于列联表，其中每个变量有两个以上的类别。

例如，让我们看看 NHANES 的数据，并比较变量*抑郁*，它表示“参与者自我报告的感到情绪低落、抑郁或绝望的天数”。该变量编码为`None`、`Several`或`Most`。让我们来测试这个变量是否与 *SleepTrouble* 变量相关，后者表示个人是否向医生报告了睡眠问题。

<caption>Table 12.4: Relationship between depression and sleep problems in the NHANES dataset</caption>
| 沮丧的 | 无睡眠问题 | 是睡眠问题 |
| --- | --- | --- |
| 没有人 | Two thousand six hundred and fourteen | Six hundred and seventy-six |
| 几个 | Four hundred and eighteen | Two hundred and forty-nine |
| 最 | One hundred and thirty-eight | One hundred and forty-five |

仅仅通过查看这些数据，我们就可以知道这两个变量之间很可能存在关系；值得注意的是，虽然有睡眠问题的总人数比没有睡眠问题的人少得多，但对于大多数时间都感到抑郁的人来说，有睡眠问题的人数比没有睡眠问题的人多。我们可以使用卡方检验直接对此进行量化:

```
## 
##  Pearson's Chi-squared test
## 
## data:  depressedSleepTroubleTable
## X-squared = 191, df = 2, p-value <2e-16
```

这项测试表明，抑郁症和睡眠问题之间有很大的关系。我们还可以计算贝叶斯因子来量化支持替代假设的证据强度:

```
## Bayes factor analysis
## --------------
## [1] Non-indep. (a=1) : 1.8e+35 ±0%
## 
## Against denominator:
##   Null, independence, a = 1 
## ---
## Bayes factor type: BFcontingencyTable, joint multinomial
```

这里我们看到贝叶斯因子非常大(<math display="inline"><semantics><mrow><mn>1.8</mn><mo>*</mo><msup><mn>10</mn><mn>35</mn></msup></mrow><annotation encoding="application/x-tex">1.8 * 10^{35}</annotation></semantics></math>)，这表明支持抑郁与睡眠问题之间存在联系的证据非常有力。





## 当心辛普森悖论

上面给出的列联表代表了大量观察结果的汇总，但汇总有时会产生误导。让我们举一个棒球的例子。下表显示了德瑞克·基特和大卫·贾斯蒂斯在 1995-1997 年间的击球数据(击球次数和平均击球率):

<colgroup><col style="width: 12%"> <col style="width: 12%"> <col style="width: 8%"> <col style="width: 12%"> <col style="width: 8%"> <col style="width: 12%"> <col style="width: 8%"> <col style="width: 14%"> <col style="width: 8%"></colgroup> 
| 运动员 | One thousand nine hundred and ninety-five |  | One thousand nine hundred and ninety-six |  | One thousand nine hundred and ninety-seven |  | 结合的 |  |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 德瑞克·基特 | 12/48 | .250 | 183/582 | .314 | 190/654 | .291 | 385/1284 | **.300** |
| 大卫·贾斯蒂斯 | 104/411 | **.253** | 45/140 | **.321** | 163/495 | **.329** | 312/1046 | .298 |

如果你仔细观察，你会发现一些奇怪的事情正在发生:在每一年，正义的平均打击率都比杰特高，但当我们把三年的数据结合起来，杰特的平均打击率实际上比正义的高！这是一个被称为*辛普森悖论*的现象的例子，在这种现象中，出现在组合数据集中的模式可能不会出现在任何数据子集中。当另一个变量可能在不同的子集之间发生变化时，就会出现这种情况——在这种情况下，击球次数会随着年份的变化而变化，正义在 1995 年击球次数要多得多(当时击球率很低)。我们称之为*潜伏变量*，每当我们检查分类数据时，关注这些变量总是很重要的。





## 12.9 学习目标

*   描述分类数据的列联表的概念。
*   描述关联的卡方检验的概念，并计算给定列联表的卡方检验。
*   描述辛普森悖论以及为什么它对分类数据分析很重要。





## 12.10 附加读数

*   心理科学中的辛普森悖论:实用指南



